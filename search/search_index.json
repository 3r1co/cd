{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>This training material is part of the Collaborative Development Course of ISEN Toulon.</p> <p>The course takes place over four days and intends to give students an overview of all technologies that are revolving around Collaborative Development and Container technologies with a special focus on \"cloud\".</p> <p>Throughout the course, the students will learn how to:</p> <ul> <li>What are microservice architectures and what advantages do they bring</li> <li>How container technology can be used to efficiently package applications</li> <li>How to collaborate with the help of Git in a software development team</li> <li>How to specify requirements, raise issues and write documentation</li> </ul>"},{"location":"#day-1","title":"Day 1","text":"<ol> <li>Prerequisites </li> <li>Docker Lab</li> <li>Kubernetes Lab</li> <li>Getting Started on Github</li> <li>Github Actions</li> <li>CI with Github Actions and Docker</li> </ol>"},{"location":"#day-2","title":"Day 2","text":"<ol> <li>Software Bill of Materials</li> <li>Static Code Analysis</li> <li>3rd Party Dependency Check</li> <li>Container Vulnerability Scanning</li> <li>Kubernetes Network Security Policies</li> <li>Git training</li> </ol>"},{"location":"#day-3","title":"Day 3","text":"<ol> <li>The Project</li> </ol>"},{"location":"actions/","title":"Github Actions (1 hour)","text":"<p>The goal of this exercise is to show you how to create a CI/CD Pipeline for containerized applications. For this Lab, we will use the automation platform of Github, called Github Actions.</p> <p>At the end of the exercise, should have added a Github Actions YAML file to your repository and on each commit and push to the master branch, a new Docker image should be built automatically.</p> <p>Find below an example for a Github Actions pipeline. This file must be placed under <code>.github/workflows/build.yaml</code>:</p> <pre><code>name: Build App\n\non:\n    push:\n        branches:\n        - main\n\njobs:\n    build:\n        runs-on: ubuntu-latest\n        steps:\n        - uses: actions/checkout@v2\n        - name: build-push\n          uses: docker/build-push-action@v1\n          with:\n            username: ${{ secrets.DOCKER_USERNAME }}\n            password: ${{ secrets.DOCKER_PASSWORD }}\n            registry: docker.io\n            repository: &lt;your-dockerhub-username&gt;/cd\n            tag_with_sha: true\n</code></pre> <p>Take care that you need to specify your username and password in the project secrets according to this documentation: https://docs.github.com/en/actions/reference/encrypted-secrets The environment variable for your username should be <code>DOCKER_USERNAME</code>, the one for your password <code>DOCKER_PASSWORD</code>.</p> <p>As a security measure, instead of using your hub.docker.com password, you can also create an access token as described here: https://docs.docker.com/docker-hub/access-tokens/</p>"},{"location":"clair/","title":"Docker Vulnerability Scanning with Trivy (1 hour)","text":"<p>So far, we uncovered vulnerabilities in</p> <ul> <li>your application source</li> <li>third party libraries in your application</li> <li>your infrastructure as code</li> </ul> <p>Another vulnerability factor can be the libraries that are integrated in your operating system, or in the case of Docker, your Docker image.</p> <p>A famous open source vulnerability scanner for Docker images is Trivy.</p> <p>Here a way to run the Trivy scan:</p> <pre><code>- name: Run Trivy vulnerability scanner\n    uses: aquasecurity/trivy-action@master\n    with:\n      image-ref: 'docker.io/&lt;your-username&gt;/&lt;your-image&gt;:${{ github.sha }}'\n      format: 'table'\n      exit-code: '1'\n      ignore-unfixed: true\n      vuln-type: 'os,library'\n      severity: 'CRITICAL,HIGH'\n</code></pre>"},{"location":"dependency-check/","title":"Static Code Analysis with OWASP Dependency Check (1 hour)","text":"<p>After analyzing your own source code with SonarQube, the next critical step is to examine the dependencies your application relies on. </p> <p>Even if your code is secure, vulnerabilities can be introduced through third-party libraries, frameworks, and packages that your project consumes.</p> <p>To address this, one of the most widely used tools is the OWASP Dependency Check. Developed under the Open Web Application Security Project (OWASP), it is a Software Composition Analysis (SCA) tool that scans the libraries in your project and identifies known vulnerabilities. </p> <p>It does this by comparing your dependencies against the National Vulnerability Database (NVD) and other security advisories, flagging any components with reported CVEs (Common Vulnerabilities and Exposures).</p> <p>By integrating OWASP Dependency Check into your workflow, you ensure that insecure dependencies are identified early, preventing them from reaching production. This is crucial, as many high-profile breaches have been traced back to outdated or vulnerable third-party components.</p> <p>Fortunately, OWASP Dependency Check also provides a ready-to-use GitHub Action, which you can find here.</p> <p>Add the following lines to your pipeline:</p> <pre><code>- uses: 3r1co/dependency-check-action@master\n  name: OWASP Dependency Check\n  with:\n    Project-Name: TestApp\n</code></pre> <p>In this exercise, integrate this program into your Github workflow.</p> <p>You need to save your report with the following instruction:</p> <pre><code>- name: Archive dependency check reports\n  uses: actions/upload-artifact@v4\n  with:\n    name: reports\n    path: reports\n</code></pre>"},{"location":"docker/","title":"Docker Lab (1 hour)","text":"<p>The goal of this exercise is to build your first Docker container. At the end of the lab, you should have</p> <ul> <li>a functioning web server based on Node.JS</li> <li>packaged this web server in a Docker image</li> <li>a running a Docker container that you can access from your workstation</li> </ul> <p>To perform this lab:</p> <ol> <li> <p>Verify that you can log in to the global Docker Registry:  </p> <pre><code>docker login\n</code></pre> </li> <li> <p>Create a directory for this training on your Desktop (e.g. \"DevelopmentEnvironment\"). Download the following files in this directory:</p> <ul> <li>Dockerfile (the file to build the Docker image)</li> <li>app.js (the application source code)</li> </ul> </li> <li> <p>In your terminal, position yourself in the directory:</p> <pre><code>cd c:\\Users\\&lt;username&gt;\\Desktop\\DevelopmentEnvironment\n</code></pre> </li> <li> <p>Open the previously downloaded file \"Dockerfile\" in an editor:</p> <ul> <li>the first line states <code>FROM node:alpine</code><ul> <li>In case you wouldn't specify a tag (:alpine), Docker will default to \"latest\". It is a common best-practice to always specify a tag when referencing to an image.</li> </ul> </li> <li>you'll also see one line stating <code>ADD app.js .</code><ul> <li>In this step the source code of your Node.JS server is added into <code>.</code> directory, so in the current working directory.</li> </ul> </li> <li>you'll also a line with the statement <code>ENTRYPOINT</code>. The entrypoint is the command that is run on your Docker container with the it is launched with the <code>docker run</code> command.</li> </ul> </li> <li> <p>Launch the image build process:  </p> <pre><code>docker build -t mywebserver:1.0 .\n</code></pre> </li> <li> <p>The Docker Engine has now built a new Docker image and you can find it in your local registry. To do so, type the following in your terminal:  </p> <pre><code>docker images\n</code></pre> </li> <li> <p>Run the previously built image:  </p> <pre><code>docker run -d --rm -p 3000:3000 mywebserver:1.0\n</code></pre> <p>The id of the container is returned. The container is started in the background.</p> <p>Notes on the parameters: </p> <ul> <li>\"-d\" instructs Docker to run the container as a daemon, so in the background</li> <li>\"--rm\" instructs Docker to delete the container ones it is stopped. Like that, the local registry will not be poluted with \"intermediate\" containers</li> <li>\"-p 3000:3000\" instructs Docker to expose the containers port 3000 on port 3000 on the host (Attention: in our case, the host is the Minikube VM)</li> </ul> </li> <li> <p>You can check the logs of your running container with:  </p> <pre><code>docker logs &lt;id of the container&gt;\n</code></pre> </li> <li> <p>In your browser, open http://localhost:3000.    You should see \"Hello World\" now.</p> </li> <li> <p>Once you are satisfied with the result, you can transfer your image from local Docker registry to the global Docker registry. Do do so, tag your image and push it to docker.io:</p> <pre><code>docker tag mywebserver:1.0 &lt;username&gt;/mywebserver:1.0 \ndocker push &lt;username&gt;/mywebserver:1.0\n</code></pre> <p>Attention: For this to work, you will need an account on hub.docker.com</p> </li> <li> <p>You can now stop your container (with the id of the container that was returned to you when you ran it)  </p> <pre><code>docker stop  &lt;id of the container&gt;\n</code></pre> </li> </ol>"},{"location":"docker/#follow-up-exercise-30-minutes","title":"Follow up exercise (30 Minutes)","text":"<p>After you learned how to build, run and push a Docker image, try to build the same application you saw here in another programming language.</p> <p>Check out the Golang example as well:</p> <ul> <li>Dockerfile (the file to build the Docker image)</li> <li>app.go (the application source code)</li> </ul>"},{"location":"ecr/","title":"CI with Github Actions and Docker (1 hour)","text":"<p>This exercise is building up on exercise 1.4 (Github Actions).</p> <p>The goal of this exercise is to push your previously built Docker image to the public Docker hub: hub.docker.com</p> <p>Performing this step is absolutely necessary for most of the following exercises.</p> <p>The goal of this exercise is to extend your your Github Actions to:</p> <ul> <li>Use the Github Action provided by Docker (see documentation here)</li> <li>Push your image with a unique tag to hub.docker.com (use the <code>GITHUB_SHA</code> environment variable)</li> </ul>"},{"location":"git/","title":"Git","text":"<p>In order to succeed in collaborative development, it's important to know the basics about Git In this practice section, please work in pairs:</p> <ul> <li>Each of you creates a new Git repository</li> <li>Create a feature branch with the command <code>git checkout -b a-new-feature</code></li> <li>Create a new file, add it (with <code>git add .</code>) and commit it to the new branch (with <code>git commit -am \"Adding a new file\"</code>)</li> <li>Push the new branch to Github.com</li> <li>Fork the repository of your peer</li> <li>Create a feature branch in the forked repository</li> <li>Push the changes in the feature branch to Github.com</li> <li>Open a Pull request to the original repository</li> </ul>"},{"location":"github/","title":"Getting started with Github (1 hour)","text":"<p>The goal of this exercise is to upload your current progress into a version control system.</p> <p>For this course, we are using Github.com as a our platform. Within the next one hour, please perform the following steps:</p> <ol> <li>Sign Up to Github.com</li> <li>Install git on your workstation</li> <li>Create a new repository with the name \"cd\". It will serve as the base for the following days and all changes will be stored here</li> <li>Follow the instructions on how to add existing source code into your newly created repository. Perform the indicated steps in the previously created \"DevelopmentEnvironment\" folder on your workstation</li> <li>Push your source code into your repository</li> </ol> <p>Once this is done, you can take the remaining time and get familiar with the Gitflow best practice here.</p> <p>Ideally, for future labs you will create a new branch for exery exercise and merge it to the Git master through a \"Pull Request\".</p>"},{"location":"kubernetes/","title":"Kubernetes Lab (1 hour)","text":"<p>In this lab, you will deploy your previously created Docker image in Kubernetes. The goal of this lab is to</p> <ul> <li>show you the usage of Kubernetes deployments and services</li> <li>how to use Kubernetes scaling capabilites</li> <li>how to access a service deployed in Kubernetes</li> </ul>"},{"location":"kubernetes/#application-deployment","title":"Application Deployment","text":"<ol> <li> <p>Verify that you can access Kubernetes:  </p> <pre><code>kubectl version\n</code></pre> <p>If you see a <code>Server Version</code> like below, it means your Kubernetes CLI can connect to your Kubernetes VM:</p> <pre><code>$ kubectl version\nClient Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.10\", GitCommit:\"37d169313237cb4ceb2cc4bef300f2ae3053c1a2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T10:52:43Z\", GoVersion:\"go1.11.13\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.10\", GitCommit:\"37d169313237cb4ceb2cc4bef300f2ae3053c1a2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T10:44:49Z\", GoVersion:\"go1.11.13\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n</code></pre> </li> <li> <p>Download the following file to your \"DevelopmentEnvironment\" folder:  </p> <ul> <li>deployment.yaml </li> </ul> </li> <li> <p>Open the file in an editor and verify that the <code>image:</code> key is referencing your previously built image</p> </li> <li> <p>Deploy your application with the following command:  </p> <pre><code>kubectl apply -f deployment.yaml\n</code></pre> </li> <li> <p>Verify that your application is running properly:  </p> <pre><code>kubectl get deployment\n</code></pre> <p>You shoud now see one running Pod, which is scheduled by the Deployment that you just created.</p> </li> <li> <p>You can also check the running Pods in your Kubernetes cluster by typing:  </p> <pre><code>kubectl get pods\n</code></pre> <p>This will give a list of running instances (a.k.a. Pods) of your application. Write down the name of the Pod, you'll need it later for reference.</p> </li> <li> <p>In order to access your application, you have to deploy a Kubernetes service.  Download the following file your \"DevelopmentEnvironment\" folder: </p> <ul> <li>service.yaml </li> </ul> <p>and apply the following command:    </p> <pre><code>kubectl apply -f service.yaml\n</code></pre> </li> <li> <p>You have now deployed a so called NodePort Kubernetes Service. It opens a dedicated port on your Minikube VM, through which you can access the according service. You can find the associated port number by typing:  </p> <pre><code>kubectl get svc\n</code></pre> <p>In the example below, the port number would be 31478:</p> <pre><code>$ kubectl get svc  \nNAME                TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE  \nkubernetes          ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP        126d\nwebserver-service   NodePort    10.98.147.142    &lt;none&gt;        80:31478/TCP   4s\n</code></pre> </li> <li> <p>In your browser, open http://localhost:xxxxx and add the port that you retrieved from the last command, e.g.:    http://localhost:31478.    You should see \"Hello World\" example from before, but it's hosted in Kubernetes.    You should also see that the hostname is equal to the Pod name that you wrote down earlier.</p> </li> </ol>"},{"location":"kubernetes/#application-scaling","title":"Application Scaling","text":"<ol> <li> <p>Now you'll see the scaling capabilities of Kubernetes. Enter the following command:  </p> <pre><code>kubectl scale deployment/webserver-deployment --replicas=3\n</code></pre> <p>With this command, you update the Kubernetes Deployment and instruct it to have a total of three replicas. Kubernetes will handle that by instantiating two additional Pods. </p> </li> <li> <p>Refresh your browser serveral times and monitor how the hostname of your microservice changes.    Congratulations, you just learned how to scale a service in Kubernetes.</p> </li> </ol>"},{"location":"kubernetes/#application-configuration","title":"Application Configuration","text":"<ol> <li> <p>For the next step, we we'll see how to configure an application in Kubernetes.    You might have noticed that in the <code>app.js</code> file, we are defining an environment variable GREETING with the default value Hello World.    In a first step, we will change the Kubernetes the Kubernetes deployment and add environment variable section the Pod template:  </p> <pre><code>kubectl edit deployment webserver-deployment\n</code></pre> <p>and add the env section like described below:</p> <pre><code>spec:\ncontainers:\n- image: mywebserver:1.0\n  imagePullPolicy: IfNotPresent\n  name: webserver\n  env:\n  - name: GREETING\n    value: \"I'm configured now\"\n</code></pre> </li> <li> <p>Refresh your browser, and see how to greeting changed.</p> </li> <li> <p>Now let's use another mean to configure our application: the Kubernetes ConfigMap. Download the sample ConfigMap to your \"DevelopmentEnvironment\" folder:  </p> <ul> <li>configmap.yaml</li> </ul> <p>This way, you can decouple the application from the deployment configuration and therefore ease the reusability of your application. You can deploy the ConfigMap with the following command:  </p> <pre><code>kubectl apply -f configmap.yaml\n</code></pre> </li> <li> <p>Now, you'll have to modify your deployment in order to consume the ConfigMap:</p> <pre><code>kubectl edit deployment webserver-deployment\n</code></pre> <p>And edit the file in the following way:</p> <pre><code>spec:\ncontainers:\n- image: mywebserver:1.0\n    imagePullPolicy: IfNotPresent\n    name: webserver\n    env:\n    - name: GREETING\n      valueFrom:\n        configMapKeyRef:\n          name: webserver-configmap\n          key: greeting\n</code></pre> </li> </ol>"},{"location":"kubernetes/#application-secrets","title":"Application Secrets","text":"<p>Kubernetes also supports objects of the type Secret, that are meant to store sensitive data. Secrets can either be injected as environment variables or mounted in the Pods filesystem. As you already learned how to inject environment variables, let's now inject the Kubernetes secret as a file into our pod.</p> <ol> <li> <p>Deploy a secret in our Kubernetes cluster: </p> <pre><code>kubectl create secret generic webserver-secret --from-literal=secret.txt=\"Well done!\"\n</code></pre> </li> <li> <p>Update your Pod definiton to mount the webserver-secret secret in /var/secret/:</p> <pre><code>kubectl edit deployment webserver-deployment\n</code></pre> <p>And edit the file in the following way:</p> <pre><code>containers: # exists already\n- image: mywebserver:1.0 # exists already\n  imagePullPolicy: IfNotPresent # exists already\n  name: webserver # exists already\n  volumeMounts:\n  - name: webserver-secret # References the name of the volume specified below\n    mountPath: \"/var/secret\"\n    readOnly: true\nvolumes:\n- name: webserver-secret\n  secret:\n    secretName: webserver-secret # References the secret name from step 1\n    optional: false\n</code></pre> </li> <li> <p>Refresh your browser, and see how the greeting changed.</p> </li> </ol>"},{"location":"kubernetes/#follow-up-exercise-30-minutes","title":"Follow up exercise (30 Minutes)","text":"<p>Try to launch a database in Kubernetes and connect an application with this database. A simple example can be found here. It's written in Golang and uses Redis.</p>"},{"location":"network-policies/","title":"Kubernetes Network Policies (30 minutes)","text":"<p>You need to use Minikube, not Docker Desktop for this exercise.</p> <p>As you saw throughout the course, Kubernetes separates projects through the notion of namespaces.</p> <p>By default, Kubernetes enables Pods to communicate between namespaces, which goes against of the security principles that you learned about earlier: Least privilege. As a reminder, it is a security best practice to only allow the absolute necessary.</p> <p>There is a very good Github project visualizing the different network policy configurations here.</p> <p>Your exercise is the apply the different configurations and test them accordingly. It should give you a good overview on how to apply Kubernetes network policies in real life.</p>"},{"location":"prerequisites/","title":"Prerequisites (1 hour)","text":"<p>Please follow the instructions on this page carefully, as they will help you avoiding obstacles in the next exercices.  </p> <p>The goal of the prerequisite step is to provide you a fully working development environment, containing Docker and Kubernetes.</p> <p>Please install Docker Desktop. After installing, also enable Kubernetes in the settings, as it will be part of following exercises.</p> <ol> <li> <p>Verify that you can access the Docker CLI:  </p> <pre><code>docker info\n</code></pre> </li> <li> <p>Verify that you can access the Kubernetes CLI:</p> <pre><code>kubectl version\n</code></pre> </li> </ol> <p>Below you can see an diagram of your workstation setup, which should help you understanding how the different components are interacting:  </p> <p></p>"},{"location":"prerequisites/#alternative-setup-guide","title":"Alternative Setup Guide","text":"<p>Sometimes it can happen that Docker Desktop does not run your computer. In this case, we can try the alternative approach below:</p> <ul> <li>Install Chocolatey, a Package Manager for Windows</li> <li>With Chocolatey, you will install the following packages on your workstation:  <ul> <li>VirtualBox, a VM Manager</li> <li>Docker CLI and Kubernetes CLI</li> <li>Minikube, a tool that helps you installing a Docker and Kubernetes Development environment</li> <li>Python, a programming language that you'll need later in the course</li> <li>AWS CLI, you'll need it later in the course</li> </ul> </li> <li>With Minikube, you will install a Virtual Machine in VirtualBox, containing Docker and Kubernetes</li> </ul> <p>The diagram on the bottom of this page is designed to help you to understand how Windows, your VM, Docker and Kubernetes are interacting.</p> <p>To perform this lab:</p> <ol> <li> <p>Install Chocolatey according to the instructions here. You do not have to enter your email address in the first step.  </p> </li> <li> <p>Launch a terminal with Windows Administrator rights and install Minikube, Kubectl (the Kubernetes CLI) and the Docker CLI with the help of Chocolatey:  </p> <pre><code>choco install -y python virtualbox minikube kubernetes-cli docker awscli\n</code></pre> </li> <li> <p>Launch Minikube:  </p> <pre><code>minikube --docker-env HTTP_PROXY=\"http://&lt;isen-proxy-host&gt;:&lt;isen-proxy-port&gt;\" --docker-env HTTPS_PROXY=\"http://&lt;isen-proxy-host&gt;:&lt;isen-proxy-port&gt;\" --docker-env NO_PROXY=\"127.0.0.1,192.168.99.0/24,10.0.0.0/8\" start\n</code></pre> <p>Notes on the parameters: </p> <ul> <li> <p>As we are in a universtiy network, we need to configure docker engine in the virtual machine to perform outgoing internet connection through this proxy.</p> <ul> <li> <p>Certain hosts do not need to be accessed through the proxy, which is configured through the \"NO_PROXY\" parameter. In our case, this is:  </p> <ul> <li>localhost (127.0.0.1)</li> <li>the network between your local VMs (192.168.99.0/24), </li> <li>the network range normally used for intranet (10.0.0.0/8)</li> </ul> </li> </ul> </li> </ul> <p>In order for Minikube to download the according VM image, you may have to configure the proxy on your workstation as well:  </p> <ul> <li> <p>For Windows Terminal:  </p> <pre><code>set HTTP_PROXY=http://&lt;isen-proxy-host&gt;:&lt;isen-proxy-port&gt;\nset HTTPS_PROXY=http://&lt;isen-proxy-host&gt;:&lt;isen-proxy-port&gt;\nset NO_PROXY=127.0.0.1,192.168.99.0/24,10.0.0.0/8\n</code></pre> </li> <li> <p>For Shell (Cygwin, Git Bash):  </p> <pre><code>export HTTP_PROXY=http://&lt;isen-proxy-host&gt;:&lt;isen-proxy-port&gt;\nexport HTTPS_PROXY=http://&lt;isen-proxy-host&gt;:&lt;isen-proxy-port&gt;\nexport NO_PROXY=127.0.0.1,192.168.99.0/24,10.0.0.0/8\n</code></pre> </li> </ul> </li> <li> <p>After Minikube is launched, it can be necessary to configure your Docker CLI and Kubernetes CLI on your workstation.    This configuration is done through environment variables, which can be set with the following commands: This has to be done every time you open a new terminal.</p> <ul> <li> <p>For Windows Terminal:  </p> <pre><code>@FOR /f \"tokens=*\" %i IN ('minikube docker-env') DO @%i\n</code></pre> </li> <li> <p>For Shell (Cygwin, Git Bash):  </p> <pre><code>eval(minikube docker-env)\n</code></pre> <p>or     eval $(minikube docker-env)</p> </li> </ul> </li> </ol>"},{"location":"project/","title":"The Project","text":"<p>You have been tasked to build the next-generation cloud-native library system for your university.</p> <p>Your client wants you build this library system with a microservice architecture, as they cannot foresee how successful the system will be and what could be the potential load. The client would like to have the following use cases covered:</p> <ul> <li>Lifecycle Management for students who can borrow books<ul> <li>This lifecycle management system should cover registration of new users, log in functionality and removal of accounts</li> </ul> </li> <li>Inventory system for all books available, including author, description, year of publishing<ul> <li>This system should cover creation, update and delete functionality of books</li> </ul> </li> <li>Lending system that tracks the usage of a book by given user over time<ul> <li>This system should also ensure that a book cannot be borrowed more than once at a given time</li> </ul> </li> <li>A notification system that retrieves books close to the defined end of lending date and notifies the user to bring the book back (via e-mail)<ul> <li>This system should run on a regular basis and also provide a status to the administrator of a book lease is expired</li> </ul> </li> <li>A WebUI that allows users to register, log in, search for books, lend a book, see which books they have borrowed and when they need to give it back</li> <li>An admin WebUI that allows to add new books into the system and to see which books are expired<ul> <li>The administrator needs to authenticate through the lifecycle management service, but only certain users must have admin rights</li> </ul> </li> </ul> <p>These six microservices should be developed by teams of three or four students each.</p> <p>Your client whishes that</p> <ul> <li>All microservices are built through an automated pipeline and pushed as Docker containers to hub.docker.com</li> <li>These Docker containers must not run as root</li> <li>All microservices have to have a unit test coverage of more than 70%</li> <li>All microservices have to be deployed in Kubernetes</li> <li>All microservices have to be indepedently scalable</li> <li>All microservices have to configurable through environment variables, e.g. connection string to a database</li> <li>Have to be well documented and contain instructions in the Readme.md on<ul> <li>How to deploy the microservice</li> <li>How to read log files</li> <li>How to configure it</li> </ul> </li> <li>The Kubernetes environment in which you deploy your microservices must be properly secured and communication between microservices should be permitted only when necessary</li> </ul> <p>In order to succeed, please</p> <ul> <li>Create one Github repository per microservice</li> <li>Track your requirements in Github through the opening of issues<ul> <li>You can mark an issue as resolved once the requirement is implemented and all the points above have been met</li> </ul> </li> <li>In case you requirement something specific from another microservice team, raise an issue in Github and describe the desired functionality</li> </ul> <p></p>"},{"location":"psp/","title":"Kubernetes Pod Security Policies (30 minutes)","text":"<p>In order to start, please read carefully the instructions on Pod Security Policies in EKS provided here</p> <p>You will have to delete the default eks.privileged Pod Security Policy before you can apply the example provided below.</p> <p>Please follow the example provided by Kubernetes here</p> <p>Please revert your Pod Security Policy to the standard eks.privileged after you performed the exercise. The description how to do so is mentioned on the bottom of the first page.</p>"},{"location":"sbom/","title":"Building a GitHub Actions Workflow to Generate SBOMs for a JavaScript Project and Docker Image","text":"<p>In this tutorial, you will create a GitHub Actions workflow that: - Analyzes a JavaScript project to generate a Software Bill of Materials (SBOM). - Builds a Docker image for the project. - Generates an SBOM for the Docker image, including the Node.js runtime.</p> <p>This tutorial uses Anchore's SBOM Action to generate the SBOM for the JavaScript project and to generate the SBOM for the Docker image.</p>"},{"location":"sbom/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure you have the following tools: - GitHub repository containing a JavaScript project with a <code>package.json</code> file. - Dockerfile for building the project. - Node.js and NPM installed in your project.</p>"},{"location":"sbom/#step-1-project-structure","title":"Step 1: Project Structure","text":"<p>Here is the basic structure of your project directory:</p> <pre><code>.\n\u251c\u2500\u2500 .github\n\u2502   \u2514\u2500\u2500 workflows\n\u2502       \u2514\u2500\u2500 sbom-docker.yml  # GitHub Actions workflow file\n\u251c\u2500\u2500 Dockerfile                # Dockerfile to build your app\n\u251c\u2500\u2500 package.json              # JavaScript dependencies\n\u2514\u2500\u2500 index.js                  # Your application code\n</code></pre> <p>Add the package.json:</p> <pre><code>{\n    \"name\": \"simple-webserver\",\n    \"version\": \"1.0.0\",\n    \"description\": \"A simple web server with outdated dependencies\",\n    \"main\": \"index.js\",\n    \"scripts\": {\n      \"start\": \"node index.js\"\n    },\n    \"dependencies\": {\n      \"express\": \"4.16.4\",\n      \"lodash\": \"4.17.20\"\n    },\n    \"engines\": {\n      \"node\": \"&gt;=10.0.0\"\n    },\n    \"author\": \"Your Name\",\n    \"license\": \"MIT\"\n  }\n</code></pre> <p>Add the index.js:</p> <pre><code>// index.js\nconst express = require('express');\nconst _ = require('lodash');\n\nconst app = express();\nconst port = 3000;\n\n// A simple route that responds with \"Hello, World!\"\napp.get('/', (req, res) =&gt; {\n  res.send('Hello, World!');\n});\n\n// Example of using lodash (an outdated dependency)\napp.get('/lodash-example', (req, res) =&gt; {\n  const numbers = [1, 2, 3, 4, 5];\n  const doubled = _.map(numbers, num =&gt; num * 2);\n  res.send(`Doubled Numbers: ${doubled}`);\n});\n\n// Start the web server\napp.listen(port, () =&gt; {\n  console.log(`Server is running on http://localhost:${port}`);\n});\n</code></pre>"},{"location":"sbom/#step-2-dockerfile-example","title":"Step 2: Dockerfile Example","text":"<p>Here\u2019s a simple <code>Dockerfile</code> that builds a Node.js project:</p> <pre><code># Use official Node.js runtime as a parent image\nFROM node:16-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Copy package.json and install dependencies\nCOPY package.json ./\nRUN npm install\n\n# Copy the rest of the application code\nCOPY . .\n\n# Start the application\nCMD [\"node\", \"index.js\"]\n</code></pre> <p>This Dockerfile installs dependencies from the <code>package.json</code> file and runs the application using <code>index.js</code>.</p>"},{"location":"sbom/#step-3-github-actions-workflow-using-anchore-sbom-action","title":"Step 3: GitHub Actions Workflow Using Anchore SBOM Action","text":"<p>Create a GitHub Actions workflow file at <code>.github/workflows/sbom-docker.yml</code>:</p> <pre><code>name: Build and Analyze SBOM\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  generate-sbom:\n    name: Generate SBOM and Build Docker Image\n    runs-on: ubuntu-latest\n\n    steps:\n    # Step 1: Checkout the code\n    - name: Checkout code\n      uses: actions/checkout@v4\n\n    # Step 2: Set up Node.js\n    - name: Set up Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: '22'\n\n    # Step 3: Install dependencies\n    - name: Install NPM dependencies\n      run: npm install\n\n    # Step 6: Generate SBOM for Javascript using Anchore's SBOM Action\n    - name: Generate SBOM for Docker image\n      uses: anchore/sbom-action@v0\n      with:\n        format: spdx-json\n        artifact-name: sbom-node-js.json\n\n    # Step 5: Build Docker image\n    - name: Build Docker Image\n      run: |\n        docker build -t my-node-app:latest .\n\n    # Step 6: Generate SBOM for Docker image using Anchore's SBOM Action\n    - name: Generate SBOM for Docker image\n      uses: anchore/sbom-action@v0\n      with:\n        image: my-node-app:latest\n        format: spdx-json\n        artifact-name: sbom-docker-image.json\n</code></pre>"},{"location":"sbom/#explanation-of-workflow-steps","title":"Explanation of Workflow Steps","text":"<ol> <li>Checkout code: This step checks out the repository\u2019s code so that the workflow can access it.</li> <li>Set up Node.js: This action installs Node.js (version 16) in the workflow environment.</li> <li>Install NPM dependencies: Installs the required dependencies listed in <code>package.json</code> using <code>npm install</code>.</li> <li>Build Docker image: Builds a Docker image using the <code>Dockerfile</code> and tags it as <code>my-node-app:latest</code>.</li> <li>Generate SBOM for Docker image: Uses the official Anchore SBOM Action (<code>anchore/sbom-action</code>) to generate an SBOM for the Docker image, including all the components and the Node.js runtime. The SBOM is saved as <code>sbom-docker-image.json</code>.</li> <li>Upload SBOMs as artifacts: This step uploads the generated SBOMs as artifacts so they can be downloaded and reviewed later.</li> </ol>"},{"location":"sbom/#step-4-running-the-workflow","title":"Step 4: Running the Workflow","text":"<p>Once the workflow is configured, it will automatically run when: - You push changes to the <code>main</code> branch. - You open or update a pull request targeting the <code>main</code> branch.</p>"},{"location":"sbom/#sbom-output-files","title":"SBOM Output Files:","text":"<ul> <li>sbom-node-js.json: Contains the SBOM for the JavaScript dependencies.</li> <li>sbom-docker-image.json: Contains the SBOM for the Docker image, including the Node.js runtime and other system components.</li> </ul>"},{"location":"sbom/#step-5-accessing-the-sbom-artifacts","title":"Step 5: Accessing the SBOM Artifacts","text":"<p>After the workflow runs successfully, you can download the SBOMs from the workflow run\u2019s Artifacts section on the GitHub Actions page.</p> <p>What do realize about the two files? Why would you think one is bigger than the other?</p> <p>Download both artifacts and analyze them here.</p>"},{"location":"sbom/#conclusion","title":"Conclusion","text":"<p>By setting up this GitHub Actions workflow, you\u2019ve automated the process of: - Generating an SBOM for your JavaScript project using Anchore. - Building a Docker image. - Generating an SBOM for the Docker image (including the Node.js runtime) using Anchore\u2019s SBOM Action.</p> <p>This setup helps ensure that your project follows best practices for software supply chain security by maintaining transparency and traceability of all components used in your software.</p> <p>For more information about Anchore's SBOM Action, visit the Anchore SBOM Action GitHub repository.</p>"},{"location":"sbom/#references","title":"References","text":"<ul> <li>Anchore SBOM Action</li> <li>Docker Documentation</li> </ul>"},{"location":"sonar/","title":"Static Code Analysis with Sonar (1 hour)","text":"<p>The very first layer of security and quality assurance in any application lies within its source code. Writing functional code is not enough\u2014developers must ensure that their codebase remains secure, reliable, and maintainable over time.</p> <p>This is where SonarQube comes in. SonarQube is a widely adopted static code analysis tool that inspects your code for bugs, vulnerabilities, code smells, and maintainability issues. </p> <p>By scanning your repository, it provides actionable insights to improve code quality, reduce security risks, and enforce consistent coding standards.</p> <p>To make the process seamless, SonarQube offers a GitHub Action that integrates directly into your continuous integration (CI) pipeline. </p> <p>By running this action, your source code is analyzed automatically whenever you push changes, ensuring that issues are caught early\u2014before any resources are deployed to AWS or production environments.</p> <p>For this tutorial, you\u2019ll use SonarCloud (the hosted version of SonarQube) to set up scanning. After creating an account on sonarcloud.io, you will integrate the GitHub Action into your workflow. Once configured, every build will be validated through Sonar before proceeding, and you\u2019ll be responsible for addressing any issues flagged by the scanner.</p> <p>The first thing you need to scan in your application is your actual source code.</p> <p>One very famous tool to do so is Sonarqube. There is already a Github Action available for this tool here.</p> <p>For this tutorial, you need to create an account on sonarcloud.io.</p> <ol> <li>Create a SonarCloud Account<ol> <li>Go to sonarcloud.io.</li> <li>Sign up with your GitHub account to enable direct integration.</li> <li>Create a new project in SonarCloud linked to your GitHub repository.</li> </ol> </li> <li>Generate a Token for Authentication<ol> <li>In SonarCloud, go to My Account \u2192 Security \u2192 Generate Tokens.</li> <li>Copy the generated token (this will serve as your authentication key).</li> <li>In your GitHub repository, add this token as a secret under:<pre><code>Settings \u2192 Secrets and variables \u2192 Actions \u2192 New repository secret\nName it SONAR_TOKEN.\n</code></pre> </li> </ol> </li> </ol>"},{"location":"zapproxy/","title":"Dynamic Application Security Scanning (1 hour)","text":"<p>Until now you scanned your application in a static way, meaning you found vulnerabilties before an artifact was actually built.</p> <p>A complementary way to uncover weaknesses is the Dynamic Application Security Scanning, also known as DAST.</p> <p>One famous scanner is the OWASP ZAP Proxy.</p> <p>Your task is now to integrate the ZAP Proxy Github Action here in your Github workflow.</p>"}]}